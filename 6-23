lambda x: x+1
def f(x):
  return x+1


switching [] to () turns an object into an iterator, where before it was iterable

y=map(lambda v:v*5, x)
  this means apply this transformation to every element in x
the map function is iterator, iterable

iterable has iter
iterator has next
indexable has getnext
count has count

x = [2, 3, 4]
y = [v * 5 for v in x]            # list comprehension
assert isinstance(y, list)
assert not hasattr(y, "__next__")
assert     hasattr(y, "__iter__")
assert x == [2,   3,  4]
assert y == [10, 15, 20]

x=[2,3,4]
y=(v*5 for v in x)
y is a generator
x+=[5]      adds 5 to the end of x list, because y is a generator 
list(y) = [10,15,20,25]
list(y) = []
x+=[5]
list(y) = []

iterator is lazy, exhaustible

if y has square brackets, it is eager and not lazy and only sticks to [2,3,4]



filter(lambda v:v%2,x)
filters x to only odd values

|= is the union function where you combine elements of two lists
set
dictionary comprehension






what is considered true in python
assert all([])
assert all([
    A(),
    True,
    2,
    3.45,
    "abc",
    [2, 3, 4],
    (2, 3, 4),
    {2, 3, 4},
    {2 : "abc", 3 : "def", 4 : "ghi"}])



assert not any([])
assert not any([B(), False, 0, 0.0,  "", [], (), set(), {}])





how to create generator?
def f():
print("abc")
return 5
print("def")
>>> v=f()
abc
>>> v
5




def f():
print("abc")
yield 5
print("def")

>>> v=f()
>>>
>>> w = next(v)          stimulatse function to go all the way down until it hits yield
abc
>>> w
5
when you put yield in a function it becomes a generator
  creates a factory and returns a pointer to it
  yield is like return but it returns a lazy, exhaustible generator



iterators are not guaranteed to be indexable
it might be infinite, such as count
iterator that is empty, an if statement will give you true because it's an object
















